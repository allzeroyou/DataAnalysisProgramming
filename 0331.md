# preview
```python
if __name__ == '__main__':
    main()
```
파일이 다수가 있을 때 main이 되는 파일이 어디냐라는 걸 정할 때 사용하는 함수이다.

- breaking point
![](https://images.velog.io/images/allzeroyou/post/e0a9bf2e-c86b-42d4-a0a6-f3f340bedd08/image.png)
F8> 실행결과를 return 받아 그 다음으로 넘어간다.
F7> 함수 안에 들어간 실행결과를 보고싶으면 f7를 누르면 된다.

네이버에서 제공하는 api말고 일반 웹페이지에서 데이터를 추출하고 싶을때는 어떻게 해야할까?
웹 페이지가 어떻게 구성되어있는지, html 태그 등을 잘 알고있어야 한다.

# 정적 vs 동적
정적: static, 움직이지 않는다. 변하지 않는 것을 의미.

url > dns(domain name services)

`ping www.naver.com`
어딘가에 접속을 해서 데이터를 받아와야, ping이라는 신호를 보내 dns 서버에게 물어본다.
>
pc: 데이터를 받으려면 어디에 요청을 해야돼?
dns: 너가 요청한 신호는 [223.130.200.107]이야~

웹 브라우저가 dns 서버에 물어보고 url request을 한다음, 화면을 보여주는 html 정보를 보내준다.
변경되지 않는 정보를 보여주는 것이 정적웹페이지이다.
예를 들어 유튜브의 경우, 새로고침을 할때마다  새로운 영상이 업데이트된다.
네이버 지도의 경우, 선택한 지역별로 새로운 지도맵을 보여준다.
사용자 input에 따른 새로운 정보들을 제공하는 웹 페이지가 동적 웹페이지이다.

# BeautifulSoup
html 페이지를 json이나 엑셀처럼 구조화된 정보로 처리를 해준다.
```python
 pip install beautifulsoup4

```
을 눌러 beautifulsoup4를 설치한다.
```
from bs4 import BeautifulSoup
```
그냥 import 하지 않고 이렇게 한 이유는 다른 기능을 말고 'bs4라는 해당하는 함수만 쓰겠다! 라는 뜻이다.

![](https://images.velog.io/images/allzeroyou/post/954bb4df-3c29-417c-84f5-3fb363566470/image.png)
![](https://images.velog.io/images/allzeroyou/post/1a9ac99a-093c-4cd8-8ed2-765b18976eac/image.png)

![](https://images.velog.io/images/allzeroyou/post/9ec1a7c2-8ed1-4e28-a296-998d0e2c952a/image.png)
![](https://images.velog.io/images/allzeroyou/post/dea4c994-07ac-40f3-8441-f72502857b9f/image.png)
h1 태그가 하나만 있을 경우에는 soup.h1도 가능하지만
h1 태그가 두개 이상일 경우에는 soup.find('h1')으로 작성하자.
![](https://images.velog.io/images/allzeroyou/post/c7e69640-40e2-4846-9957-713440000f40/image.png)

find 할 경우 제일 첫번째 있는 태그만 걸린다.
find_all할 경우 html 문서에 있는 해당 태그가 모두 걸린다.
(https://seungjuitmemo.tistory.com/203)

![](https://images.velog.io/images/allzeroyou/post/f49fd744-94de-40cd-85d9-d96ab5618955/image.png)
ul 태그가 2개인데, find 할 경우 첫번째 ul이 걸린다.

![](https://images.velog.io/images/allzeroyou/post/b2e4ed11-434e-47e4-b34c-57b533d41849/image.png)
find_all로 li 태그들을 모두 가져온 모습이다.
대괄호 안에 li 태그들이 콤마(,)로 구분되어 있다.

속성을 이용해 파싱하기
1) attrs: **속성 이름**과 **속성값으로** **딕셔너리** 구성
2) find(): 속성을 이용해 특정 태그 파싱
3) select(): 지정한 태그를 모두 파싱해 리스트 구성
> 
태그이름#id 속성값
태그이름.class 속성값

![](https://images.velog.io/images/allzeroyou/post/dfd7ecad-cf65-4b3f-b070-ed2484babd4c/image.png)
양파처럼 까도 까도 계속 나올 수 있음 주의.

```최종 코드
from bs4 import BeautifulSoup

# 작성한 html 문서를 읽어오기
with open ('beautifulSoup.html', 'r', encoding='utf-8') as outfile:
    html = outfile.read()

# parse 구문분석하겠다.
# bs에서 제공하는 parser 3~4개인데, default인 html.parser을 사용하겠음

soup = BeautifulSoup(html, 'html.parser')

'''
tag_a = soup.find("a")
print(tag_a.attrs)
print(tag_a['href'])

# class는 파이썬 '예약어'라 clas라는 변수를 사용할 땐 '_(언더바)'를 붙여주자
# class_ = 'brand' 이렇게 작성

print(soup.find(class_='brand').find_all('li'))
'''

# li_list는 리터러블한 객체
li_list = soup.select("div>ul.brand>li")

print(li_list)

for li in li_list:
    print(li.string)

    # print(li.text)
    # print(li.get_text())
    # 위 세개는 모두 결과가 동일함

```